{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPVSbJ3d+oa1V1KkwPt5xaC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/manu14357/Chat-With-PDF-AI/blob/main/Chat_with_PDF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Fhj2K5C2dTD",
        "outputId": "37404d96-c376-4976-80b0-131136a00437"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.57.4)\n",
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.8.2)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.10.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.27.1)\n",
            "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n"
          ]
        }
      ],
      "source": [
        "pip install openai PyPDF2\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import PyPDF2\n",
        "\n",
        "def extract_pdf_text(pdf_path):\n",
        "    with open(pdf_path, 'rb') as file:\n",
        "        reader = PyPDF2.PdfReader(file)\n",
        "        text = \"\"\n",
        "        for page in reader.pages:\n",
        "            text += page.extract_text()\n",
        "        return text\n"
      ],
      "metadata": {
        "id": "CFR_MITK7juV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import PyPDF2\n",
        "\n",
        "def extract_pdf_text(pdf_path):\n",
        "    with open(pdf_path, 'rb') as file:\n",
        "        reader = PyPDF2.PdfReader(file)\n",
        "        text = \"\"\n",
        "        for page in reader.pages:\n",
        "            text += page.extract_text()\n",
        "        return text\n"
      ],
      "metadata": {
        "id": "rvPNDbGQ7mGM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import PyPDF2\n",
        "from openai import OpenAI\n",
        "\n",
        "# Function to extract text from PDF\n",
        "def extract_pdf_text(pdf_path):\n",
        "    with open(pdf_path, 'rb') as file:\n",
        "        reader = PyPDF2.PdfReader(file)\n",
        "        text = \"\"\n",
        "        for page in reader.pages:\n",
        "            text += page.extract_text()\n",
        "        return text\n",
        "\n",
        "# Function to chunk text into smaller pieces\n",
        "def chunk_text(text, chunk_size=500):\n",
        "    words = text.split()\n",
        "    chunks = [' '.join(words[i:i + chunk_size]) for i in range(0, len(words), chunk_size)]\n",
        "    return chunks\n",
        "\n",
        "# Function to interact with NVIDIA's API\n",
        "def chat_with_pdf(pdf_chunks, user_query):\n",
        "    # Initialize the NVIDIA API client\n",
        "    client = OpenAI(\n",
        "        base_url=\"https://integrate.api.nvidia.com/v1\",\n",
        "        api_key=\"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\"\n",
        "    )\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant that answers questions based on provided PDF content.\"},\n",
        "        {\"role\": \"user\", \"content\": f\"The following content is from a PDF:\\n\\n{pdf_chunks[0]}\"},\n",
        "        {\"role\": \"user\", \"content\": user_query}\n",
        "    ]\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"nvidia/llama-3.1-nemotron-70b-instruct\",\n",
        "        messages=messages,\n",
        "        temperature=0.5,\n",
        "        top_p=1,\n",
        "        max_tokens=1024\n",
        "    )\n",
        "\n",
        "    # Access the content attribute directly\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "# Main function to tie everything together\n",
        "def main():\n",
        "    pdf_path = \"pdfo.pdf\"  # Replace with your PDF path\n",
        "    pdf_text = extract_pdf_text(pdf_path)\n",
        "    pdf_chunks = chunk_text(pdf_text)\n",
        "\n",
        "    print(\"PDF loaded successfully!\")\n",
        "\n",
        "    while True:\n",
        "        user_query = input(\"\\nEnter your question (or 'exit' to quit): \")\n",
        "        if user_query.lower() == \"exit\":\n",
        "            print(\"Goodbye!\")\n",
        "            break\n",
        "\n",
        "        response = chat_with_pdf(pdf_chunks, user_query)\n",
        "        print(\"\\nAI Response:\")\n",
        "        print(response)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "v_OVZw9e8WmO",
        "outputId": "6790cbdc-d4ea-448c-e102-a4181a767735"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PDF loaded successfully!\n",
            "\n",
            "Enter your question (or 'exit' to quit): Explain about Service Oriented Architecture? \n",
            "\n",
            "AI Response:\n",
            "Based on the provided PDF content, here's an explanation of Service Oriented Architecture (SOA):\n",
            "\n",
            "**What is Service Oriented Architecture (SOA)?**\n",
            "\n",
            "* **Definition:** SOA is a design pattern for building distributed systems that deliver services to other applications through a protocol.\n",
            "* **Key Aspect:** It's a concept, not limited to any programming language or platform.\n",
            "\n",
            "**Core Components of SOA:**\n",
            "\n",
            "1. **Service:**\n",
            "\t* A well-defined, self-contained function representing a unit of functionality.\n",
            "\t* Can exchange information with another service.\n",
            "\t* Not dependent on the state of another service.\n",
            "\n",
            "**Service Connections:**\n",
            "\n",
            "* **Interaction:**\n",
            "\t1. **Service Consumer** sends a **Service Request** to the **Service Provider**.\n",
            "\t2. **Service Provider** sends the **Service Response** to the **Service Consumer**.\n",
            "* **Characteristic:** The service connection is understandable to both the Service Consumer and Service Provider.\n",
            "\n",
            "**Characteristics of SOA Services:**\n",
            "\n",
            "1. **Loosely Coupled**\n",
            "2. **Message-based Communication**\n",
            "3. **Location-Transparent**\n",
            "4. **Self-Contained**\n",
            "\n",
            "**Service Oriented Architecture Stack:**\n",
            "\n",
            "* Categorized into two parts:\n",
            "\t1. **Functional Aspects:**\n",
            "\t\t* **Services**: Logical entities defined by one or more published interfaces.\n",
            "\t\t* **Service Provider**: Implements a service specification.\n",
            "\t\t* **Service Consumer** (Requester/Client): Calls a Service Provider (can be another service or end-user application).\n",
            "\t\t* **Service Locator** (Registry): Examines service provider interfaces and locations.\n",
            "\t\t* **Service Broker**: Passes service requests to one or more additional Service Providers.\n",
            "\t\t* **Transport**: Transports service requests and responses between Service Consumer and Service Provider.\n",
            "\t2. **Quality of Service Aspects** (not extensively detailed in the provided PDF snippet, but typically includes aspects like security, scalability, reliability, etc.)\n",
            "\n",
            "**Benefits of SOA (Advantages):**\n",
            "\n",
            "* Listed in the PDF, but not extensively detailed in the provided snippet. However, common advantages of SOA include:\n",
            "\t+ Increased interoperability\n",
            "\t+ Improved flexibility\n",
            "\t+ Enhanced reusability\n",
            "\t+ Better scalability\n",
            "\t+ Easier integration\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-53fab7788d6f>\u001b[0m in \u001b[0;36m<cell line: 62>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-5-53fab7788d6f>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0muser_query\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nEnter your question (or 'exit' to quit): \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0muser_query\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"exit\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Goodbye!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import PyPDF2\n",
        "from openai import OpenAI\n",
        "\n",
        "# Function to download the PDF from a URL\n",
        "def download_pdf_from_url(pdf_url, save_path):\n",
        "    \"\"\"Download the PDF file from the given URL and save it locally.\"\"\"\n",
        "    response = requests.get(pdf_url)\n",
        "    if response.status_code == 200:\n",
        "        with open(save_path, 'wb') as file:\n",
        "            file.write(response.content)\n",
        "            print(f\"PDF downloaded successfully and saved to {save_path}\")\n",
        "    else:\n",
        "        raise Exception(f\"Failed to download PDF. Status code: {response.status_code}\")\n",
        "\n",
        "# Function to extract text from a PDF file\n",
        "def extract_pdf_text(pdf_path):\n",
        "    with open(pdf_path, 'rb') as file:\n",
        "        reader = PyPDF2.PdfReader(file)\n",
        "        text = \"\"\n",
        "        for page in reader.pages:\n",
        "            text += page.extract_text()\n",
        "        return text\n",
        "\n",
        "# Function to chunk text into smaller pieces\n",
        "def chunk_text(text, chunk_size=500):\n",
        "    words = text.split()\n",
        "    chunks = [' '.join(words[i:i + chunk_size]) for i in range(0, len(words), chunk_size)]\n",
        "    return chunks\n",
        "\n",
        "# Function to interact with NVIDIA's API\n",
        "def chat_with_pdf(pdf_chunks, user_query, api_client):\n",
        "    \"\"\"Send a user query along with PDF chunks to NVIDIA's API and get the response.\"\"\"\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant that answers questions based on provided PDF content.\"},\n",
        "        {\"role\": \"user\", \"content\": f\"The following content is from a PDF:\\n\\n{pdf_chunks[0]}\"},\n",
        "        {\"role\": \"user\", \"content\": user_query}\n",
        "    ]\n",
        "\n",
        "    completion = api_client.chat.completions.create(\n",
        "        model=\"meta/llama-3.1-405b-instruct\",\n",
        "        messages=messages,\n",
        "        temperature=0.2,\n",
        "        top_p=0.7,\n",
        "        max_tokens=1024,\n",
        "        stream=True\n",
        "    )\n",
        "\n",
        "    response_text = \"\"\n",
        "    for chunk in completion:\n",
        "        if chunk.choices[0].delta.content is not None:\n",
        "            response_text += chunk.choices[0].delta.content\n",
        "\n",
        "    return response_text\n",
        "\n",
        "# Main function to tie everything together\n",
        "def main():\n",
        "    pdf_url = input(\"Enter the PDF URL: \")\n",
        "    pdf_path = \"downloaded_pdf.pdf\"  # Local path to save the downloaded PDF\n",
        "\n",
        "    try:\n",
        "        download_pdf_from_url(pdf_url, pdf_path)\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "        return\n",
        "\n",
        "    pdf_text = extract_pdf_text(pdf_path)\n",
        "    pdf_chunks = chunk_text(pdf_text)\n",
        "\n",
        "    print(\"PDF loaded successfully and ready for chatting!\")\n",
        "\n",
        "    # Initialize NVIDIA OpenAI client\n",
        "    api_client = OpenAI(\n",
        "        base_url=\"https://integrate.api.nvidia.com/v1\",\n",
        "        api_key=\"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\"  # Replace with your actual API key securely\n",
        "    )\n",
        "\n",
        "    while True:\n",
        "        user_query = input(\"\\nEnter your question (or 'exit' to quit): \")\n",
        "        if user_query.lower() == \"exit\":\n",
        "            print(\"Goodbye!\")\n",
        "            break\n",
        "\n",
        "        try:\n",
        "            response = chat_with_pdf(pdf_chunks, user_query, api_client)\n",
        "            print(\"\\nAI Response:\")\n",
        "            print(response)\n",
        "        except Exception as e:\n",
        "            print(f\"Error during API call: {e}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "s1i0T-0c70it",
        "outputId": "8128312a-6bef-47f4-cab8-6b0b88b33d45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the PDF URL: https://utfs.io/f/0583aeb5-be72-4610-882c-086450a6e805-cn4wpd.pdf\n",
            "PDF downloaded successfully and saved to downloaded_pdf.pdf\n",
            "PDF loaded successfully and ready for chatting!\n",
            "\n",
            "Enter your question (or 'exit' to quit): hi\n",
            "\n",
            "AI Response:\n",
            "I'm here to help answer any questions you have based on the provided PDF content about Manohar Choppa's profile. What would you like to know?\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-3bf4b4fe55b5>\u001b[0m in \u001b[0;36m<cell line: 91>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-7-3bf4b4fe55b5>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0muser_query\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nEnter your question (or 'exit' to quit): \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0muser_query\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"exit\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Goodbye!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "from PyPDF2 import PdfReader\n",
        "\n",
        "def download_pdf(pdf_url, save_path=\"downloaded_pdf.pdf\"):\n",
        "    try:\n",
        "        response = requests.get(pdf_url)\n",
        "        response.raise_for_status()\n",
        "        with open(save_path, 'wb') as file:\n",
        "            file.write(response.content)\n",
        "        print(\"PDF downloaded successfully and saved to\", save_path)\n",
        "        return save_path\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(\"Failed to download PDF:\", e)\n",
        "        return None\n",
        "\n",
        "def extract_pdf_text(pdf_path):\n",
        "    try:\n",
        "        reader = PdfReader(pdf_path)\n",
        "        text = \"\".join(page.extract_text() for page in reader.pages)\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        print(\"Error reading PDF:\", e)\n",
        "        return \"\"\n",
        "\n",
        "def chunk_text(text, chunk_size=500):\n",
        "    words = text.split()\n",
        "    return [' '.join(words[i:i + chunk_size]) for i in range(0, len(words), chunk_size)]\n",
        "\n",
        "def search_pdf_chunks(chunks, keyword):\n",
        "    results = []\n",
        "    for i, chunk in enumerate(chunks):\n",
        "        if keyword.lower() in chunk.lower():\n",
        "            results.append((i, chunk))\n",
        "    return results\n",
        "\n",
        "def summarize_text(chunks):\n",
        "    # Summarize the entire text using NVIDIA API (example code, placeholder)\n",
        "    return \"Summary feature is under development.\"\n",
        "\n",
        "def chat_with_pdf(pdf_chunks, user_query, api_key):\n",
        "    try:\n",
        "        messages = [\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant answering questions based on provided PDF content.\"},\n",
        "            {\"role\": \"user\", \"content\": f\"The following content is from a PDF:\\n\\n{pdf_chunks[0]}\"},\n",
        "            {\"role\": \"user\", \"content\": user_query}\n",
        "        ]\n",
        "\n",
        "        response = requests.post(\n",
        "            \"https://integrate.api.nvidia.com/v1/chat/completions\",\n",
        "            headers={\"Authorization\": f\"Bearer {api_key}\"},\n",
        "            json={\"model\": \"nvidia/llama-3.1-nemotron-70b-instruct\", \"messages\": messages, \"max_tokens\": 1024}\n",
        "        )\n",
        "        response.raise_for_status()\n",
        "        data = response.json()\n",
        "        return data['choices'][0]['message']['content']\n",
        "    except Exception as e:\n",
        "        print(\"Error communicating with NVIDIA API:\", e)\n",
        "        return \"An error occurred. Please try again.\"\n",
        "\n",
        "def main():\n",
        "    pdf_url = input(\"Enter the PDF URL: \")\n",
        "    api_key = \"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\"  # Replace with your actual NVIDIA API key\n",
        "\n",
        "    pdf_path = download_pdf(pdf_url)\n",
        "    if not pdf_path:\n",
        "        return\n",
        "\n",
        "    pdf_text = extract_pdf_text(pdf_path)\n",
        "    if not pdf_text:\n",
        "        return\n",
        "\n",
        "    pdf_chunks = chunk_text(pdf_text)\n",
        "\n",
        "    print(\"PDF loaded successfully and ready for chatting!\")\n",
        "\n",
        "    while True:\n",
        "        user_query = input(\"\\nEnter your question (or 'exit' to quit): \")\n",
        "        if user_query.lower() == \"exit\":\n",
        "            print(\"Goodbye!\")\n",
        "            break\n",
        "\n",
        "        if user_query.lower().startswith(\"search:\"):\n",
        "            keyword = user_query.split(\":\", 1)[1].strip()\n",
        "            search_results = search_pdf_chunks(pdf_chunks, keyword)\n",
        "            if search_results:\n",
        "                print(\"\\nSearch Results:\")\n",
        "                for i, result in search_results:\n",
        "                    print(f\"Chunk {i + 1}: {result[:300]}...\\n\")\n",
        "            else:\n",
        "                print(\"No results found for the keyword.\")\n",
        "        elif user_query.lower() == \"summarize\":\n",
        "            summary = summarize_text(pdf_chunks)\n",
        "            print(\"\\nPDF Summary:\")\n",
        "            print(summary)\n",
        "        else:\n",
        "            response = chat_with_pdf(pdf_chunks, user_query, api_key)\n",
        "            print(\"\\nAI Response:\")\n",
        "            print(response)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 720
        },
        "id": "DtG11eHNAUZ9",
        "outputId": "544327de-9f42-4e9f-a6b6-51ded261c280"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the PDF URL: https://utfs.io/f/37e05cc3-e76e-4180-8407-b82c0b104f5d-ujzuhg.pdf\n",
            "PDF downloaded successfully and saved to downloaded_pdf.pdf\n",
            "PDF loaded successfully and ready for chatting!\n",
            "\n",
            "Enter your question (or 'exit' to quit): Hi\n",
            "\n",
            "AI Response:\n",
            "Hello!\n",
            "\n",
            "Welcome to our Q&A session based on Akhila Kada's profile summary PDF. I'm here to help. Please feel free to ask me any questions you have about Akhila's:\n",
            "\n",
            "1. **Skills** (Programming Languages, Technologies & Tools, Machine Learning Algorithms)\n",
            "2. **Education** (Academic background, Institutions)\n",
            "3. **Certifications** (Microsoft, Skill Dzire, IBM)\n",
            "4. **Internships** (AWS Cloud Internship experience)\n",
            "5. **Additional Information** (Online trainings, Projects, Leadership skills)\n",
            "6. **Final Year Project** (Neural Networks for Detecting Misinformation in Modern Media)\n",
            "\n",
            "What would you like to know? Go ahead and ask your question!\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-d24a0f6ec919>\u001b[0m in \u001b[0;36m<cell line: 101>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-6-d24a0f6ec919>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0muser_query\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nEnter your question (or 'exit' to quit): \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0muser_query\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"exit\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Goodbye!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install gradio\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wxqcj0gfBTQx",
        "outputId": "a143f02d-7e19-435d-8f34-b122af5047cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradio\n",
            "  Downloading gradio-5.8.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
            "  Downloading fastapi-0.115.6-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.4.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting gradio-client==1.5.1 (from gradio)\n",
            "  Downloading gradio_client-1.5.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.28.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.25.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.26.3)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.4)\n",
            "Collecting markupsafe~=2.0 (from gradio)\n",
            "  Downloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.26.4)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.10.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (11.0.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.10.3)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.18 (from gradio)\n",
            "  Downloading python_multipart-0.0.19-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.2)\n",
            "Collecting ruff>=0.2.2 (from gradio)\n",
            "  Downloading ruff-0.8.2-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
            "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.41.3-py3-none-any.whl.metadata (6.0 kB)\n",
            "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.15.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.12.2)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.32.1-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.5.1->gradio) (2024.10.0)\n",
            "Collecting websockets<15.0,>=10.0 (from gradio-client==1.5.1->gradio)\n",
            "  Downloading websockets-14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (3.16.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (4.66.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.27.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (2.2.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading gradio-5.8.0-py3-none-any.whl (57.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.2/57.2 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.5.1-py3-none-any.whl (320 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.2/320.2 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading fastapi-0.115.6-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Downloading python_multipart-0.0.19-py3-none-any.whl (24 kB)\n",
            "Downloading ruff-0.8.2-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.2/11.2 MB\u001b[0m \u001b[31m92.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading starlette-0.41.3-py3-none-any.whl (73 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.2/73.2 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
            "Downloading uvicorn-0.32.1-py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.8/63.8 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.4.0-py3-none-any.whl (5.8 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Downloading websockets-14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.2/168.2 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pydub, websockets, uvicorn, tomlkit, semantic-version, ruff, python-multipart, markupsafe, ffmpy, aiofiles, starlette, safehttpx, gradio-client, fastapi, gradio\n",
            "  Attempting uninstall: markupsafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "Successfully installed aiofiles-23.2.1 fastapi-0.115.6 ffmpy-0.4.0 gradio-5.8.0 gradio-client-1.5.1 markupsafe-2.1.5 pydub-0.25.1 python-multipart-0.0.19 ruff-0.8.2 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.41.3 tomlkit-0.13.2 uvicorn-0.32.1 websockets-14.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "from PyPDF2 import PdfReader\n",
        "import gradio as gr\n",
        "\n",
        "def download_pdf(pdf_url, save_path=\"downloaded_pdf.pdf\"):\n",
        "    try:\n",
        "        response = requests.get(pdf_url)\n",
        "        response.raise_for_status()\n",
        "        with open(save_path, 'wb') as file:\n",
        "            file.write(response.content)\n",
        "        print(\"PDF downloaded successfully and saved to\", save_path)\n",
        "        return save_path\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(\"Failed to download PDF:\", e)\n",
        "        return None\n",
        "\n",
        "def extract_pdf_text(pdf_path):\n",
        "    try:\n",
        "        reader = PdfReader(pdf_path)\n",
        "        text = \"\".join(page.extract_text() for page in reader.pages)\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        print(\"Error reading PDF:\", e)\n",
        "        return \"\"\n",
        "\n",
        "def chunk_text(text, chunk_size=500):\n",
        "    words = text.split()\n",
        "    return [' '.join(words[i:i + chunk_size]) for i in range(0, len(words), chunk_size)]\n",
        "\n",
        "def search_pdf_chunks(chunks, keyword):\n",
        "    results = []\n",
        "    for i, chunk in enumerate(chunks):\n",
        "        if keyword.lower() in chunk.lower():\n",
        "            results.append((i, chunk))\n",
        "    return results\n",
        "\n",
        "def summarize_text(chunks):\n",
        "    # Placeholder for summarization logic\n",
        "    return \"This is a placeholder for the PDF summary.\"\n",
        "\n",
        "def chat_with_pdf(pdf_chunks, user_query, api_key):\n",
        "    try:\n",
        "        messages = [\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant answering questions based on provided PDF content.\"},\n",
        "            {\"role\": \"user\", \"content\": f\"The following content is from a PDF:\\n\\n{pdf_chunks[0]}\"},\n",
        "            {\"role\": \"user\", \"content\": user_query}\n",
        "        ]\n",
        "\n",
        "        response = requests.post(\n",
        "            \"https://integrate.api.nvidia.com/v1/chat/completions\",\n",
        "            headers={\"Authorization\": f\"Bearer {api_key}\"},\n",
        "            json={\"model\": \"nvidia/llama-3.1-nemotron-70b-instruct\", \"messages\": messages, \"max_tokens\": 1024}\n",
        "        )\n",
        "        response.raise_for_status()\n",
        "        data = response.json()\n",
        "        return data['choices'][0]['message']['content']\n",
        "    except Exception as e:\n",
        "        print(\"Error communicating with NVIDIA API:\", e)\n",
        "        return \"An error occurred. Please try again.\"\n",
        "\n",
        "def process_query(pdf_url, user_query, api_key):\n",
        "    pdf_path = download_pdf(pdf_url)\n",
        "    if not pdf_path:\n",
        "        return \"Failed to download PDF.\"\n",
        "\n",
        "    pdf_text = extract_pdf_text(pdf_path)\n",
        "    if not pdf_text:\n",
        "        return \"Failed to extract text from PDF.\"\n",
        "\n",
        "    pdf_chunks = chunk_text(pdf_text)\n",
        "\n",
        "    if user_query.lower().startswith(\"search:\"):\n",
        "        keyword = user_query.split(\":\", 1)[1].strip()\n",
        "        search_results = search_pdf_chunks(pdf_chunks, keyword)\n",
        "        if search_results:\n",
        "            return \"\\n\".join([f\"Chunk {i + 1}: {result[:300]}...\" for i, result in search_results])\n",
        "        else:\n",
        "            return \"No results found for the keyword.\"\n",
        "    elif user_query.lower() == \"summarize\":\n",
        "        return summarize_text(pdf_chunks)\n",
        "    else:\n",
        "        return chat_with_pdf(pdf_chunks, user_query, api_key)\n",
        "\n",
        "def continuous_chat(pdf_url, api_key):\n",
        "    pdf_path = download_pdf(pdf_url)\n",
        "    if not pdf_path:\n",
        "        return \"Failed to download PDF.\"\n",
        "\n",
        "    pdf_text = extract_pdf_text(pdf_path)\n",
        "    if not pdf_text:\n",
        "        return \"Failed to extract text from PDF.\"\n",
        "\n",
        "    pdf_chunks = chunk_text(pdf_text)\n",
        "    context = []\n",
        "\n",
        "    def chat_fn(user_query):\n",
        "        if user_query.lower() == \"reset\":\n",
        "            context.clear()\n",
        "            return \"Context reset.\"\n",
        "\n",
        "        messages = [\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant answering questions based on provided PDF content.\"}\n",
        "        ]\n",
        "        messages.extend(context)\n",
        "        messages.append({\"role\": \"user\", \"content\": user_query})\n",
        "\n",
        "        try:\n",
        "            response = requests.post(\n",
        "                \"https://integrate.api.nvidia.com/v1/chat/completions\",\n",
        "                headers={\"Authorization\": f\"Bearer {api_key}\"},\n",
        "                json={\"model\": \"nvidia/llama-3.1-nemotron-70b-instruct\", \"messages\": messages, \"max_tokens\": 1024}\n",
        "            )\n",
        "            response.raise_for_status()\n",
        "            data = response.json()\n",
        "            reply = data['choices'][0]['message']['content']\n",
        "            context.append({\"role\": \"user\", \"content\": user_query})\n",
        "            context.append({\"role\": \"assistant\", \"content\": reply})\n",
        "            return reply\n",
        "        except Exception as e:\n",
        "            return f\"Error communicating with NVIDIA API: {e}\"\n",
        "\n",
        "    return chat_fn\n",
        "\n",
        "def gradio_interface():\n",
        "    api_key = \"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\"  # Replace with your actual NVIDIA API key\n",
        "\n",
        "    def process(pdf_url, user_query):\n",
        "        return process_query(pdf_url, user_query, api_key)\n",
        "\n",
        "    def continuous_chat_mode(pdf_url):\n",
        "        return continuous_chat(pdf_url, api_key)\n",
        "\n",
        "    chat_fn = gr.Interface(\n",
        "        fn=process,\n",
        "        inputs=[\"text\", \"text\"],\n",
        "        outputs=\"text\",\n",
        "        title=\"Chat with PDF\"\n",
        "    )\n",
        "\n",
        "    continuous_fn = gr.Interface(\n",
        "        fn=continuous_chat_mode,\n",
        "        inputs=\"text\",\n",
        "        outputs=\"text\",\n",
        "        title=\"Continuous Chat with PDF\"\n",
        "    )\n",
        "\n",
        "    gr.TabbedInterface([chat_fn, continuous_fn], [\"Single Query\", \"Continuous Chat\"]).launch()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    gradio_interface()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 650
        },
        "id": "u3lyfq-jBWos",
        "outputId": "d6544532-8db0-4f57-dd4e-850b2ba14fb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://6635f3b0900b464d52.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://6635f3b0900b464d52.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}